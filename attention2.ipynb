{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# create a cnn model as attention model\n",
    "# load classifier model\n",
    "# integrate the attention and classifier model\n",
    "# compare with and without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# data\n",
    "import data as limitedData\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# models\n",
    "from models import Wide_ResNet, VAE, SimpleNN3\n",
    "\n",
    "# datetime\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "# optimizer\n",
    "from ranger import Ranger\n",
    "\n",
    "# visualization\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "# os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# better print\n",
    "from termcolor import cprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed setup\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jack/SSL/data.py\", line 322, in <module>\n",
      "    summary()\n",
      "  File \"/home/jack/SSL/data.py\", line 272, in summary\n",
      "    - All data:           {numOfAllData}\n",
      "NameError: name 'numOfAllData' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initExperiment(config):\n",
    "    \n",
    "    # initialize data\n",
    "    limitedData.init(config)\n",
    "\n",
    "    global EXPERIMENT_NAME\n",
    "    global ACC_LOSS_SAVE_PATH\n",
    "    global MODEL_SAVE_PATH\n",
    "    global supervisedModel\n",
    "    global criterionForSupervisedModel\n",
    "    global optimizerForSupervisedModel\n",
    "    global LOG                \n",
    "    global LR\n",
    "    global OPTIM                 \n",
    "    global NUM_PL         \n",
    "    global NUM_EPOCH          \n",
    "    global NUM_ROUND          \n",
    "    global MAX_ESC   \n",
    "    global accumulate_gradient\n",
    "    global train_batch\n",
    "    global train_batch_after_accumulate\n",
    "    global accumulate_iter \n",
    "    \n",
    "    # configure cpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # configure hyperparameters\n",
    "    LOG = config['hp']['log']\n",
    "    LR = config['hp']['lr']\n",
    "    NUM_PL = config['hp']['num_pl']\n",
    "    NUM_EPOCH = config['hp']['num_epoch']\n",
    "    print(NUM_EPOCH)\n",
    "    NUM_ROUND = config['hp']['num_round']\n",
    "    MAX_ESC = config['hp']['max_esc']\n",
    "    train_batch = config['hp']['train_batch']\n",
    "    \n",
    "    # accumulate gradient\n",
    "    accumulate_gradient = config['hp']['accumulate_gradient']\n",
    "    train_batch_after_accumulate = config['hp']['train_batch_after_accumulate']\n",
    "    accumulate_iter = int(train_batch_after_accumulate / train_batch)\n",
    "\n",
    "    tpe = pytz.timezone('Asia/Taipei')\n",
    "    EXPERIMENT_NAME = datetime.now(tpe).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    OPTIM = config['hp']['optimizer']\n",
    "\n",
    "    print(limitedData.N_CLASS)\n",
    "    print(limitedData.RESIZE_SHAPE)\n",
    "    print(device)\n",
    "    supervisedModel = Wide_ResNet(28, 10, 0.2, limitedData.N_CLASS, data_shape=limitedData.RESIZE_SHAPE)\n",
    "    if config['hp']['pretrained']:\n",
    "        checkpoint = torch.load(config['path']['pretrained_S'])\n",
    "        supervisedModel.load_state_dict(checkpoint['state_dict'])\n",
    "    supervisedModel.to(device)\n",
    "    supervisedModel = torch.nn.DataParallel(supervisedModel)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    criterionForSupervisedModel = torch.nn.CrossEntropyLoss()\n",
    "    if config['hp']['optimizer'] == 'Ranger':\n",
    "        optimizerForSupervisedModel = Ranger(supervisedModel.parameters(), lr=LR, alpha=0.5, k=6, N_sma_threshhold=5, betas=(.95, 0.999), eps=1e-5, weight_decay=0, use_gc=True, gc_conv_only=False)\n",
    "    else:\n",
    "        optimizerForSupervisedModel = torch.optim.Adam(supervisedModel.parameters(), lr=LR)\n",
    "    ACC_LOSS_SAVE_PATH = f'./records/{config[\"hp\"][\"dataset\"]}/S/{config[\"hp\"][\"optimizer\"]}/{EXPERIMENT_NAME}'\n",
    "    MODEL_SAVE_PATH = f'./checkpoints/{config[\"hp\"][\"dataset\"]}/S/{config[\"hp\"][\"optimizer\"]}/{EXPERIMENT_NAME}'\n",
    "    Path(ACC_LOSS_SAVE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    Path(MODEL_SAVE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    # copyfile(src='./config.yaml', dst=f'{ACC_LOSS_SAVE_PATH}/config.yaml')\n",
    "    with open(f'{ACC_LOSS_SAVE_PATH}/config.yaml', 'w') as outfile:\n",
    "        yaml.dump(config, outfile)\n",
    "\n",
    "def log(model):\n",
    "    global statistics\n",
    "    global ACC_LOSS_SAVE_PATH\n",
    "\n",
    "    if model == \"supervisedModel\":\n",
    "        with open(f'{ACC_LOSS_SAVE_PATH}/sAcc', 'a+') as f:\n",
    "            f.write(str(statistics.trainAcc) + ',')\n",
    "            f.write(str(statistics.valAcc  ) + ',')\n",
    "            f.write(str(statistics.testAcc ) + '\\n')\n",
    "        with open(f'{ACC_LOSS_SAVE_PATH}/sLoss', 'a+') as f:\n",
    "            f.write(str(statistics.trainLoss) + ',')\n",
    "            f.write(str(statistics.valLoss  ) + ',')\n",
    "            f.write(str(statistics.testLoss ) + '\\n')\n",
    "    elif model == \"mainClassifier\":\n",
    "        with open(f'{ACC_LOSS_SAVE_PATH}/mAcc', 'a+') as f:\n",
    "            f.write(str(statistics.trainAcc) + ',')\n",
    "            f.write(str(statistics.valAcc  ) + ',')\n",
    "            f.write(str(statistics.testAcc ) + '\\n')\n",
    "        with open(f'{ACC_LOSS_SAVE_PATH}/mLoss', 'a+') as f:\n",
    "            f.write(str(statistics.trainLoss) + ',')\n",
    "            f.write(str(statistics.valLoss  ) + ',')\n",
    "            f.write(str(statistics.testLoss ) + '\\n')\n",
    "    else:\n",
    "        print(\"Warning: Undefined model\")\n",
    "\n",
    "\n",
    "def finalTestsupervisedModel():\n",
    "    global supervisedModel\n",
    "    global criterionForSupervisedModel\n",
    "    global statistics\n",
    "    statistics.reset(mode=\"test\")\n",
    "    loadModel(\"globalSupervisedModel\")\n",
    "    supervisedModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in limitedData.testDataLoaderForSupervisedModel:\n",
    "            if torch.cuda.is_available(): x, y = x.cuda(), y.cuda()\n",
    "            # Forward pass\n",
    "            y_hat, _ = supervisedModel(x)\n",
    "            loss = criterionForSupervisedModel(y_hat, y.long())\n",
    "            # Prediction\n",
    "            _, onehot = y_hat.max(1)\n",
    "            statistics.numTotal += len(y)\n",
    "            statistics.numCorrect += onehot.eq(y).sum().item()\n",
    "            statistics.valLoss += loss.item()\n",
    "        statistics.testAcc = statistics.numCorrect / statistics.numTotal\n",
    "        statistics.testLoss /= statistics.numTotal\n",
    "    \n",
    "    print('\\n---------------------------------- Summary ---------------------------------')\n",
    "    print(f'TestAcc  [{statistics.testAcc:.3%}]')\n",
    "    print(f'TestLoss [{statistics.testLoss:.6f}]')\n",
    "\n",
    "\n",
    "\n",
    "def pseudoLabel():\n",
    "    global supervisedModel\n",
    "    global NUM_PL\n",
    "\n",
    "    # limitedData.unlabeledDataset    = limitedData.MyDataset(limitedData.representationVectorsForTrain[limitedData.indicesOfUnabeledData])\n",
    "    limitedData.unlabeledDataset    = limitedData.MyDataset(limitedData.allImages[limitedData.indicesOfUnabeledData],transform=limitedData.transformWithAffine)\n",
    "    # print(len(limitedData.unlabeledDataset))\n",
    "    limitedData.unlabeledDataLoader = DataLoader(limitedData.unlabeledDataset, batch_size=limitedData.VAL_BATCH, shuffle=False, num_workers=2)\n",
    "    # print(len(limitedData.unlabeledDataLoader))\n",
    "    supervisedModel.eval()\n",
    "    confidenceList = np.array([])\n",
    "    predictedLabelList = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for x in limitedData.unlabeledDataLoader:\n",
    "            if torch.cuda.is_available(): x = x.cuda()\n",
    "            y_hat, _  = supervisedModel(x)\n",
    "            confidence, predictedLabels = y_hat.max(1)\n",
    "            confidence = confidence.detach().cpu().numpy()\n",
    "            predictedLabels = predictedLabels.detach().cpu().numpy()\n",
    "            confidenceList = np.append(arr=confidenceList, values=confidence)\n",
    "            predictedLabelList = np.append(arr=predictedLabelList, values=predictedLabels)\n",
    "\n",
    "    NUM_PL = min(len(confidenceList), NUM_PL)\n",
    "    indicesOfTopK = np.argpartition(confidenceList, -NUM_PL)[-NUM_PL:]\n",
    "    \n",
    "    indicesOfPseudolabeledData = limitedData.indicesOfUnabeledData[indicesOfTopK]\n",
    "    labelsOfPseudolabeledData  = predictedLabelList[indicesOfTopK]\n",
    "    \n",
    "    # Update train\n",
    "    limitedData.indicesOfTrainData   = np.append(arr=limitedData.indicesOfTrainData, values=indicesOfPseudolabeledData)\n",
    "    limitedData.labelsOfTrainData    = np.append(arr=limitedData.labelsOfTrainData, values=labelsOfPseudolabeledData).astype(np.int64)\n",
    "    limitedData.numOfTrainData += NUM_PL\n",
    "    \n",
    "    # Update labeled\n",
    "    limitedData.indicesOfLabeledData = np.append(arr=limitedData.indicesOfLabeledData, values=indicesOfPseudolabeledData)\n",
    "    limitedData.labelsOfLabeledData  = np.append(arr=limitedData.labelsOfLabeledData, values=labelsOfPseudolabeledData).astype(np.int64)\n",
    "    limitedData.numOfLabeledData += NUM_PL\n",
    "    \n",
    "    # Update unlabeled\n",
    "    mask = np.ones(limitedData.numOfAllData, dtype=bool)\n",
    "    mask[limitedData.indicesOfLabeledData] = False\n",
    "    limitedData.indicesOfUnabeledData = np.arange(limitedData.numOfAllData)[mask]\n",
    "    limitedData.numOfUnlabeledData -= NUM_PL\n",
    "    \n",
    "    # Update trainDataLoader\n",
    "    limitedData.trainDatasetForSupervisedModel = limitedData.MyDataset(limitedData.allImages[limitedData.indicesOfTrainData], transform=limitedData.transformWithAffine, labels=limitedData.labelsOfTrainData)\n",
    "    limitedData.trainDataLoaderForSupervisedModel = DataLoader(limitedData.trainDatasetForSupervisedModel, batch_size=limitedData.TRAIN_BATCH, shuffle=True,  num_workers=limitedData.NUM_WORKER)\n",
    "\n",
    "def summaryRound(roundID):\n",
    "    print(f'Round [{roundID}/{NUM_ROUND}]', end=' ')\n",
    "    print(f'numLabeled [{limitedData.numOfLabeledData}]', end=' ')\n",
    "    print(f'numUnlabeled [{limitedData.numOfUnlabeledData}]', end=' ')\n",
    "    print(f'numTrain [{limitedData.numOfTrainData}]', end=' ')\n",
    "    print(f'+{NUM_PL}\\n')\n",
    "\n",
    "def main_exp(config):\n",
    "    val_round =[]\n",
    "    test_round = []\n",
    "    numRound = config['hp']['num_round']\n",
    "    for roundID in range(numRound+1):\n",
    "        trainSupervisedModel()\n",
    "        val_round.append(round(statistics.localBestValAcc*100,3)) #statistics.testAcc\n",
    "        test_round.append(round(statistics.testAcc*100,3)) #statistics.testAcc\n",
    "    if LOG: plot()\n",
    "\n",
    "def plot():\n",
    "    delta = 0.1\n",
    "    fname = f'{ACC_LOSS_SAVE_PATH}'\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    \n",
    "    title = f'Acc[{statistics.testAcc:.2%}] OPT[{OPTIM}] LR[{LR}] Batch[{limitedData.TRAIN_BATCH}] EPOCH[{NUM_EPOCH}] PL[{NUM_PL}/{NUM_ROUND}]\\n{EXPERIMENT_NAME}'\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    mapper = {0:'train', 1:'val', 2:'test'}\n",
    "\n",
    "    sAcc = np.loadtxt(f'{fname}/sAcc', delimiter=',')\n",
    "    ax = fig.add_subplot(2, 2, 1)\n",
    "    ax.set_ylim(0-delta, 1+delta)\n",
    "    for i in range(3):\n",
    "        ax.plot(sAcc[:,i], label=mapper[i])\n",
    "        ax.set_title('Supervised Model Acc')\n",
    "        ax.legend()\n",
    "    \n",
    "    # mAcc = np.loadtxt(f'{fname}/mAcc', delimiter=',')\n",
    "    # ax = fig.add_subplot(2, 2, 2)\n",
    "    # ax.set_ylim(0-delta, 1+delta)\n",
    "    # for i in range(3):\n",
    "    #     ax.plot(mAcc[:,i])\n",
    "    #     ax.set_title('Main Classifier Acc')\n",
    "    \n",
    "    sLoss = np.loadtxt(f'{fname}/sLoss', delimiter=',')\n",
    "    ax = fig.add_subplot(2, 2, 3)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    for i in range(3):\n",
    "        ax.plot(sLoss[:,i])\n",
    "        ax.set_title('Supervised Model Loss')\n",
    "    \n",
    "    # mLoss = np.loadtxt(f'{fname}/mLoss', delimiter=',')\n",
    "    # ax = fig.add_subplot(2, 2, 4)\n",
    "    # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    # for i in range(3):\n",
    "    #     ax.plot(mLoss[:,i])\n",
    "    #     ax.set_title('Main Classifier Loss')\n",
    "    plt.savefig(f'{ACC_LOSS_SAVE_PATH}/{int(statistics.testAcc*1e4)}')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneTrainSupervisedModel():\n",
    "    global supervisedModel\n",
    "    global criterionForSupervisedModel\n",
    "    global optimizerForSupervisedModel\n",
    "    global statistics\n",
    "    statistics.reset(mode=\"train\")\n",
    "    supervisedModel.train()\n",
    "    for batch_idx, (x, y) in enumerate(limitedData.trainDataLoaderForSupervisedModel):\n",
    "        if torch.cuda.is_available(): x, y = x.cuda(), y.cuda()\n",
    "        # Forward pass\n",
    "        y_hat, _ = supervisedModel(x)\n",
    "        loss = criterionForSupervisedModel(y_hat, y.long())\n",
    "        if accumulate_gradient:\n",
    "            loss_accum = loss / accumulate_iter\n",
    "            loss_accum.backward()\n",
    "            if (batch_idx + 1) % accumulate_iter == 0 or batch_idx + 1 == len(limitedData.trainDataLoaderForSupervisedModel):\n",
    "                optimizerForSupervisedModel.step()\n",
    "                optimizerForSupervisedModel.zero_grad()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizerForSupervisedModel.step()\n",
    "            optimizerForSupervisedModel.zero_grad()\n",
    "        # Statistics\n",
    "        _, onehot = y_hat.max(1)\n",
    "        statistics.numTotal += len(y)\n",
    "        statistics.numCorrect += onehot.eq(y).sum().item()\n",
    "        statistics.trainLoss += loss.item()\n",
    "    statistics.trainAcc = statistics.numCorrect / statistics.numTotal\n",
    "    statistics.trainLoss /= statistics.numTotal\n",
    "\n",
    "def oneValSupervisedModel():\n",
    "    global supervisedModel\n",
    "    global criterionForSupervisedModel\n",
    "    global statistics\n",
    "    statistics.reset(mode=\"val\")\n",
    "    supervisedModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in limitedData.valDataLoaderForSupervisedModel:\n",
    "            if torch.cuda.is_available(): x, y = x.cuda(), y.cuda()\n",
    "            # Forward pass\n",
    "            y_hat, _ = supervisedModel(x)\n",
    "            loss = criterionForSupervisedModel(y_hat, y.long())\n",
    "            # Prediction\n",
    "            _, onehot = y_hat.max(1)\n",
    "            statistics.numTotal += len(y)\n",
    "            statistics.numCorrect += onehot.eq(y).sum().item()\n",
    "            statistics.valLoss += loss.item()\n",
    "        statistics.valAcc = statistics.numCorrect / statistics.numTotal\n",
    "        statistics.valLoss /= statistics.numTotal\n",
    "\n",
    "def oneTestSupervisedModel(): \n",
    "    global supervisedModel\n",
    "    global criterionForSupervisedModel\n",
    "    global statistics\n",
    "    statistics.reset(mode=\"test\")\n",
    "    if not statistics.improved: \n",
    "        saveModel(\"tempSupervisedModel\")\n",
    "        loadModel(\"supervisedModel\")\n",
    "    supervisedModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in limitedData.testDataLoaderForSupervisedModel:\n",
    "            if torch.cuda.is_available(): x, y = x.cuda(), y.cuda()\n",
    "            # Forward pass\n",
    "            y_hat, _ = supervisedModel(x)\n",
    "            loss = criterionForSupervisedModel(y_hat, y.long())\n",
    "            # Prediction\n",
    "            _, onehot = y_hat.max(1)\n",
    "            statistics.numTotal += len(y)\n",
    "            statistics.numCorrect += onehot.eq(y).sum().item()\n",
    "            statistics.testLoss += loss.item()\n",
    "        statistics.testAcc = statistics.numCorrect / statistics.numTotal\n",
    "        statistics.testLoss /= statistics.numTotal\n",
    "    if not statistics.improved: loadModel(\"tempSupervisedModel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSupervisedModel():\n",
    "    global statistics\n",
    "    statistics.initRound()\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        oneTrainSupervisedModel()\n",
    "        oneValSupervisedModel()\n",
    "        if improved(model=\"supervisedModel\", mode='local'): \n",
    "            saveModel(\"supervisedModel\")\n",
    "        # notice\n",
    "        # if improved(model=\"mainClassifier\", mode='global'): \n",
    "        if improved(model=\"supervisedModel\", mode='global'): \n",
    "            saveModel('globalSupervisedModel')\n",
    "        oneTestSupervisedModel()\n",
    "        if shouldEarlyStop(\"supervisedModel\"): break\n",
    "        summaryModel(epoch+1, \"supervisedModel\")\n",
    "        if LOG: log(\"supervisedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "    if model == 'supervisedModel' or model == \"tempSupervisedModel\" or model == \"globalSupervisedModel\":\n",
    "        global supervisedModel\n",
    "        global optimizerForSupervisedModel\n",
    "        checkpoint = {\n",
    "            'state_dict' : supervisedModel.state_dict(), \n",
    "            'optimizer' : optimizerForSupervisedModel.state_dict(),\n",
    "            }\n",
    "        torch.save(checkpoint, f'{MODEL_SAVE_PATH}/{model}.pth')\n",
    "        return\n",
    "    elif model == 'mainClassifier' or model == \"tempMainClassifier\" or model == \"globalMainClassifier\":\n",
    "        global mainClassifier\n",
    "        global optimizerForMainClassifier\n",
    "        checkpoint = {\n",
    "            'state_dict' : mainClassifier.state_dict(), \n",
    "            'optimizer' : optimizerForMainClassifier.state_dict(),\n",
    "            }\n",
    "        torch.save(checkpoint, f'{MODEL_SAVE_PATH}/{model}.pth')\n",
    "        return\n",
    "    else:\n",
    "        print(\"Warning: Undefined model\")\n",
    "\n",
    "def loadModel(model):\n",
    "    if model == \"supervisedModel\" or model == \"tempSupervisedModel\" or model == \"globalSupervisedModel\":\n",
    "        global supervisedModel\n",
    "        global optimizerForSupervisedModel\n",
    "        checkpoint = torch.load(f'{MODEL_SAVE_PATH}/{model}.pth')\n",
    "        supervisedModel.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizerForSupervisedModel.load_state_dict(checkpoint['optimizer'])\n",
    "    elif model == \"mainClassifier\" or model == \"tempMainClassifier\" or model == \"globalMainClassifier\":\n",
    "        global mainClassifier\n",
    "        global optimizerForMainClassifier\n",
    "        checkpoint = torch.load(f'{MODEL_SAVE_PATH}/{model}.pth')\n",
    "        mainClassifier.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizerForMainClassifier.load_state_dict(checkpoint['optimizer'])\n",
    "    else:\n",
    "        print(\"Warning: Undefined model\")\n",
    "\n",
    "def summaryModel(epoch, model):\n",
    "    cprint(f'Epoch [{epoch}/{NUM_EPOCH}]', end=' ')\n",
    "    cprint(f'Train [{statistics.trainAcc:.3%}]', 'yellow', end=' ')\n",
    "    cprint(f'Val [{statistics.valAcc:.3%}]', 'magenta', end=' ')\n",
    "    cprint(f'BestVal [{statistics.localBestValAcc:.3%}]', 'green', end=' ')\n",
    "    cprint(f'Test [{statistics.testAcc:.3%}]', 'cyan', end=' ')\n",
    "    if model == \"supervisedModel\":\n",
    "        cprint(f'ESC [{statistics.earlyStopCountForSupervisedModel}/{MAX_ESC}]', end=' ')\n",
    "    elif model == \"mainClassifier\":\n",
    "        cprint(f'ESC [{statistics.earlyStopCountForMainClassifier}/{MAX_ESC}]', end=' ')\n",
    "    else:\n",
    "        print(\"Warning: Undefined model\")\n",
    "    cprint('+', 'green') if statistics.improved else cprint('-', 'red')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "960e6ed259eaee5b44eb3de64476b91dbf80b8c48856b46aafe249a40eac1eb7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
